# Todo

### 19/oct
- [X] clean slate
- [X] get url contents at client side
- [X] scrape and log the first content

### 22/oct
- [X] parse each by row
- [X] write test code for the fetch-content

### 23/oct
- [X] save in csv file code segment

### 26/oct
- [X] loop fetch all
- [X] await so that contents are parsed asyncronously but added together in order

### 27/oct
- [X] save in csv with time stamp
- [X] one procedure for fetch and save as csv

### rem

#### backend
- [ ] sort content by date
- [ ] time it
- [ ] benchmark the parsing performance
- [ ] save periodical fetches if there is something new gets added
- [ ] schedule job looking maintainer
- [ ] create & save hash for each job post
- [ ] fetch from technopark
- [ ] scrape request should scrape and check if already present in the static content
- [ ] UI update based on when backend has something to update
- [ ] check hash and list new jobs with highlight

#### frontend
- [ ] list all jobs
- [ ] show new additions with a highlight
- [ ] downloadable as excel sheet, csv